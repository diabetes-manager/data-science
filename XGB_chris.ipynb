{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from scripts.data_processing import (\n",
    "    load_uci, load_tidepool_dummy, \n",
    "    load_so_pump, \n",
    "    load_so_cgm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validate(df, target_name, test_fraction=0.2):\n",
    "    test_size = int(df.shape[0] * test_fraction)\n",
    "    df_train = df.iloc[0:-test_size]\n",
    "    df_val   = df.iloc[-test_size:]\n",
    "    print(f'train size: {len(df_train)}')\n",
    "    print(f'test size: {len(df_val)}')\n",
    "    \n",
    "    X_train  = df_train.drop(columns=[target_name])\n",
    "    y_train  = df_train[target_name]\n",
    "    \n",
    "    X_val    = df_val.drop(columns=[target_name])\n",
    "    y_val    = df_val[target_name]\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "\n",
    "def preprocess(df, minutes=30, n_historical_cols=2):\n",
    "    # convert datetime to int\n",
    "    df['timestamp'] = df['timestamp'].astype(np.int64) // 10**9\n",
    "\n",
    "    for x in range(1, n_historical_cols+1):\n",
    "        df[['prev_meas', 'prev_time']] = df[['measurement', 'timestamp']].shift(x)\n",
    "        df[f'prev_trend_{x}'] = (\n",
    "            df['prev_meas'].divide(df['timestamp'] - df['prev_time']))\n",
    "        df = df.drop(columns=['prev_meas', 'prev_time'])\n",
    "\n",
    "    # get 30 minute future value\n",
    "    df = append_future_value_col(df, minutes)\n",
    "\n",
    "    # remove nans\n",
    "    og_len = len(df)\n",
    "    df = df.loc[~df[f'{minutes}_minutes'].isna() & \n",
    "                ~df[f'prev_trend_{n_historical_cols}'].isna()]\n",
    "    n_dropped = og_len - len(df)\n",
    "    assert n_dropped < (10 + n_historical_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def append_future_value_col(df, minutes):\n",
    "    seconds = minutes * 60\n",
    "    \n",
    "    df[f'{minutes}_minutes'] = np.interp(\n",
    "        df['timestamp'].add(seconds), df['timestamp'],\n",
    "        df['measurement']\n",
    "    )\n",
    "    \n",
    "    max_valid_time = df['timestamp'].max() - seconds\n",
    "    df.loc[df['timestamp'] > max_valid_time, f'{minutes}_minutes'] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute baseline MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_rmse(df, minutes=30):\n",
    "    # if we predict the same value as the current value\n",
    "    df = preprocess(df, minutes)\n",
    "    \n",
    "    mse = sum((df[f'{minutes}_minutes'] - \n",
    "               df['measurement']).pow(2)) / len(df)\n",
    "    \n",
    "    return np.sqrt(mse)\n",
    "\n",
    "\n",
    "baseline_rmse(df=load_so_cgm(), minutes=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = load_so_cgm()\n",
    "df = preprocess(df)\n",
    "\n",
    "X_train, X_val, y_train, y_val = split_train_validate(\n",
    "    df.copy(), target_name='30_minutes'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#        colsample_bytree=1, gamma=0, importance_type='gain',\n",
    "#        learning_rate=0.06, max_delta_step=0, max_depth=2,\n",
    "#        min_child_weight=1, missing=None, n_estimators=60, n_jobs=1,\n",
    "#        nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
    "#        reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "#        subsample=1)\n",
    "# gave us +/- 18.66 mg/dL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "    'learning_rate': [0.05, 0.06, 0.07, 0.08],\n",
    "    'n_estimators':  [40, 50, 60],\n",
    "    'max_depth': [2],\n",
    "#     'subsample': [0.5, 0.75, 0.9],\n",
    "#     'colsample_bytree': [0.1, 0.2, 0.3, 0.4],\n",
    "#     'gamma': [0, 1, 2]\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(XGBRegressor(),\n",
    "                          param_grid=param_grid, \n",
    "                          # scoring='roc_auc', \n",
    "                          cv=3, n_jobs=-1,\n",
    "                          return_train_score=True, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gridsearch.cv_results_['mean_train_score'].mean(),\n",
    "      gridsearch.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gridsearch.predict(X_val)\n",
    "print('mae:', mean_absolute_error(y_val, y_pred))\n",
    "print('rmse:', np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, minutes=30):\n",
    "    # pull in user data\n",
    "    df = load_so_cgm()\n",
    "    # process\n",
    "    df = preprocess(df)\n",
    "    df = df.drop(columns=[f'{minutes}_minutes'])\n",
    "    # predict\n",
    "    predictions = model.predict(df)\n",
    "    \n",
    "    df = df[['timestamp']].assign(predicted_value = list(predictions))\n",
    "    df['timestamp'] = df['timestamp'] + 60 * minutes\n",
    "    \n",
    "    # TODO: make JSON or write to DB\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('diabetesmanager/model.pkl', 'wb') as f:\n",
    "    pickle.dump(gridsearch, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('diabetesmanager/model.pkl', 'rb') as f:\n",
    "    gridsearch = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
